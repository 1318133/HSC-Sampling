import numpy
import os
import scipy.io as scio
import cv2
import torch
from torch.utils.data import Dataset
import pickle
import tqdm
from tqdm.contrib import tzip
import h5py
import utils
from scipy import signal
import random

def crop_to_patch(img, size, stride):
    H, W = img.shape[:2]
    patches = []
    for h in range(0, H, stride):
        for w in range(0, W, stride):
            if h + size <= H and w + size <= W:
                patch = img[h: h + size, w: w + size, :]
                patches.append(patch)
    return patches


class MakeSimulateDatasetforDemosaic(Dataset):
    msfa_size = 4
    spatial_ratio = 2
    def __init__(self, args, type="train"):
        cache_path = os.path.join(args.cache_path, type + "_cache.pkl")
        self.train_size = args.train_size
        if not os.path.exists(cache_path):
            self.mosaic, self.target = [], []
            base_path = os.path.join(args.data_path, args.dataset, type)
            print("Cache file not found. Generate it from: ", base_path)
            hrms_imgs = os.listdir(base_path)

            for hrms_name in tqdm.tqdm(hrms_imgs):
                if args.dataset == "CAVE":
                    hrms = scio.loadmat(os.path.join(base_path, hrms_name))["b"]
                elif args.dataset == "ICVL":
                    hrms = h5py.File(os.path.join(base_path, hrms_name))["rad"][:]
                    hrms = numpy.rot90(hrms.transpose(2, 1, 0))
                    hrms /= hrms.max((0, 1))
                elif args.dataset == "NTIRE2022":
                    hrms = scio.loadmat(os.path.join(base_path, hrms_name))["cube"]
                    # img1 = img["ref"]
                    hrms = hrms / hrms.max()
                hrms_select_bands = hrms[:hrms.shape[0]//(args.msfa_size*args.spatial_ratio)*(args.msfa_size*args.spatial_ratio),
                                        :hrms.shape[1]//(args.msfa_size*args.spatial_ratio)*(args.msfa_size*args.spatial_ratio),
                                        12:28].astype(numpy.float32)

                MSFA = numpy.array([[0, 1, 2, 3],
                                    [4, 5, 6, 7],
                                    [8, 9, 10, 11],
                                    [12, 13, 14, 15]])
                hrms_tensor = torch.from_numpy(hrms_select_bands).permute(2, 0, 1).unsqueeze(0)
                lrms_tensor = torch.nn.functional.avg_pool2d(hrms_tensor, 2, 2)
                lrms = lrms_tensor[0].permute(1, 2, 0).numpy()
                mosaic = utils.MSFA_filter(lrms, MSFA)

                if type == "train":
                    mosaic_patches = crop_to_patch(mosaic, args.train_size, args.stride)

                    self.mosaic += mosaic_patches
                elif type == "test":
                    self.mosaic.append(mosaic)
                    self.target.append(lrms)

            with open(cache_path, "wb") as f:
                pickle.dump([self.mosaic, self.target], f)

        print("Load data from cache file: ", cache_path)
        with open(cache_path, "rb") as f:
            self.mosaic, self.target = pickle.load(f)

    def __len__(self):
        return len(self.mosaic)

    def __getitem__(self, index):
        if self.target == []:
            mosaic = torch.from_numpy(self.mosaic[index].astype(numpy.float32))
            mosaic = mosaic.permute(2, 0, 1)

            return mosaic
        else:
            mosaic = torch.from_numpy(self.mosaic[index].astype(numpy.float32))
            mosaic = mosaic.permute(2, 0, 1)
            target = torch.from_numpy(self.target[index].astype(numpy.float32))
            target = target.permute(2, 0, 1)

            return mosaic, target
        
class MakeRealWorldDatasetforDemosaic(Dataset):
    def __init__(self, args, type="train"):
        cache_path = os.path.join(args.cache_path, type + "_cache.pkl")
        self.train_size = args.train_size
        if not os.path.exists(cache_path):
            self.mosaic = []
            base_path = os.path.join(args.data_path, args.dataset, type)
            print("Cache file not found. Generate it from: ", base_path)
            mosaic_path = os.path.join(base_path, "mosaic")
            pan_path = os.path.join(base_path, "pan")
            mosaic_imgs = os.listdir(mosaic_path)
            mosaic_imgs.sort()
            pan_imgs = os.listdir(pan_path)
            pan_imgs.sort()
            assert len(mosaic_imgs) == len(pan_imgs), "Length mismatch between MS and PAN images!"

            for mosaic_name, pan_name in tqdm.tqdm(tzip(mosaic_imgs, pan_imgs)):
                with open(os.path.join(mosaic_path, mosaic_name), "rb") as f:
                    mosaic_raw = numpy.frombuffer(f.read(), dtype=numpy.int16)
                    mosaic = numpy.zeros((255*4, 276*4, 1))
                    for i in range(args.msfa_size):
                        for j in range(args.msfa_size):
                            mosaic[i::args.msfa_size, j::args.msfa_size, 0] = mosaic_raw[255*276*(i*args.msfa_size+j): 255*276*(i*args.msfa_size+j+1)].reshape(255, 276)
                
                for i in range(args.msfa_size):
                    for j in range(args.msfa_size):
                        mosaic[i::args.msfa_size, j::args.msfa_size, 0] = mosaic[i::args.msfa_size, j::args.msfa_size, 0] / mosaic[i::args.msfa_size, j::args.msfa_size, 0].max()
                
                if type == "train":
                    mosaic_patches = crop_to_patch(mosaic, args.train_size, args.stride)

                    self.mosaic += mosaic_patches
                elif type == "test":
                    self.mosaic.append(mosaic)

            with open(cache_path, "wb") as f:
                pickle.dump(self.mosaic, f)

        print("Load data from cache file: ", cache_path)
        with open(cache_path, "rb") as f:
            self.mosaic = pickle.load(f)

    def __len__(self):
        return len(self.mosaic)

    def __getitem__(self, index):
        mosaic = torch.from_numpy(self.mosaic[index].astype(numpy.float32)).permute(2, 0, 1)
        return mosaic

def input_matrix_wpn(inH, inW, msfa_size):

    h_offset_coord = torch.zeros(inH, inW, 1)
    w_offset_coord = torch.zeros(inH, inW, 1)
    for i in range(0,msfa_size):
        h_offset_coord[i::msfa_size, :, 0] = (i+1)/msfa_size
        w_offset_coord[:, i::msfa_size, 0] = (i+1)/msfa_size

    pos_mat = torch.cat((h_offset_coord, w_offset_coord), 2)
    pos_mat = pos_mat.contiguous().view(1, -1, 2)
    return pos_mat

class MakeSimulateDatasetforPansharpening(Dataset):
    def __init__(self, args, type="train", demosaic_net=None):
        self.train_size = args.train_size
        cache_path = os.path.join(args.cache_path, type + "_cache.pkl")
        if not os.path.exists(cache_path):
            self.mosaic, self.lrms, self.pan, self.hrms = [], [], [], []
            base_path = os.path.join(args.data_path, args.dataset, type)
            print("Cache file not found. Generate it from: ", base_path)
            hrms_imgs = os.listdir(base_path)

            for hrms_name in tqdm.tqdm(hrms_imgs):
                if args.dataset == "CAVE":
                    hrms = scio.loadmat(os.path.join(base_path, hrms_name))["b"]
                elif args.dataset == "ICVL":
                    hrms = h5py.File(os.path.join(base_path, hrms_name))["rad"][:]
                    hrms = numpy.rot90(hrms.transpose(2, 1, 0))
                    hrms /= hrms.max((0, 1))
                hrms_select_bands = hrms[:hrms.shape[0]//(args.msfa_size*args.spatial_ratio)*(args.msfa_size*args.spatial_ratio),
                                        :hrms.shape[1]//(args.msfa_size*args.spatial_ratio)*(args.msfa_size*args.spatial_ratio),
                                        12:28].astype(numpy.float32)

                MSFA = numpy.array([[0, 1, 2, 3],
                                    [4, 5, 6, 7],
                                    [8, 9, 10, 11],
                                    [12, 13, 14, 15]])
                hrms_tensor = torch.from_numpy(hrms_select_bands).permute(2, 0, 1).unsqueeze(0)
                lrms_tensor = torch.nn.functional.avg_pool2d(hrms_tensor, 2, 2)
                lrms = lrms_tensor[0].permute(1, 2, 0).numpy()
                mosaic = utils.MSFA_filter(lrms, MSFA)
                
                spe_res = numpy.array([1., 1, 2, 4, 8, 9, 10, 12, 16, 12, 10, 9, 7, 3, 2, 1])
                spe_res /= spe_res.sum()

                mosaic_tensor = torch.from_numpy(mosaic.astype(numpy.float32)).permute(2, 0, 1).unsqueeze(0).to(f"cuda:{args.device}")
                with torch.no_grad():
                    scale_coord_map = input_matrix_wpn(mosaic_tensor.shape[2], mosaic_tensor.shape[3], MSFA.shape[0]).to(mosaic_tensor.device)
                    mosaic_up = torch.zeros(mosaic_tensor.shape[0], MSFA.shape[0]*MSFA.shape[1], mosaic_tensor.shape[2], mosaic_tensor.shape[3]).to(mosaic_tensor.device)
                    for i in range(MSFA.shape[0]):
                        for j in range(MSFA.shape[1]):
                            mosaic_up[:, i*MSFA.shape[1]+j, i::MSFA.shape[0], j::MSFA.shape[1]] = mosaic_tensor[:, 0, i::MSFA.shape[0], j::MSFA.shape[1]]
                    demosaic = demosaic_net([mosaic_up, mosaic_tensor], scale_coord_map).detach()
                demosaic = demosaic[0].permute(1, 2, 0).cpu().numpy()

                pan = numpy.sum(hrms_select_bands * spe_res, axis=-1, keepdims=True)

                spatial_ratio = pan.shape[0] // demosaic.shape[0]
                if type == "train":
                    demosaic_patches = crop_to_patch(demosaic, args.train_size//spatial_ratio, args.stride//spatial_ratio)
                    pan_patches = crop_to_patch(pan, args.train_size, args.stride)

                    self.lrms += demosaic_patches
                    self.pan += pan_patches

                elif type == "test":
                    self.mosaic.append(mosaic)
                    self.lrms.append(demosaic)
                    self.pan.append(pan)
                    self.hrms.append(hrms_select_bands)

            with open(cache_path, "wb") as f:
                pickle.dump([self.mosaic, self.lrms, self.pan, self.hrms], f)

        print("Load data from cache file: ", cache_path)
        with open(cache_path, "rb") as f:
            self.mosaic, self.lrms, self.pan, self.hrms = pickle.load(f)

    def __len__(self):
        return len(self.lrms)

    def __getitem__(self, index):
        if self.hrms != []:
            mosaic = torch.from_numpy(self.mosaic[index].astype(numpy.float32))
            mosaic = mosaic.permute(2, 0, 1)
            lrms = torch.from_numpy(self.lrms[index].astype(numpy.float32))
            lrms = lrms.permute(2, 0, 1)
            pan = torch.from_numpy(self.pan[index].astype(numpy.float32))
            pan = pan.permute(2, 0, 1)
            hrms = torch.from_numpy(self.hrms[index].astype(numpy.float32))
            hrms = hrms.permute(2, 0, 1)

            return mosaic, lrms, pan, hrms
        else:
            lrms = torch.from_numpy(self.lrms[index].astype(numpy.float32))
            lrms = lrms.permute(2, 0, 1)
            pan = torch.from_numpy(self.pan[index].astype(numpy.float32))
            pan = pan.permute(2, 0, 1)

            return lrms, pan

class MakeRealWorldDatasetForPansharpening(Dataset):
    def __init__(self, args, type="train", demosaic_net=None):
        self.train_size = args.train_size
        cache_path = os.path.join(args.cache_path, type + "_cache.pkl")
        if not os.path.exists(cache_path):
            self.mosaic, self.lrms, self.pan, self.hrms = [], [], [], []
            base_path = os.path.join(args.data_path, args.dataset, type)
            print("Cache file not found. Generate it from: ", base_path)
            mosaic_path = os.path.join(base_path, "mosaic")
            pan_path = os.path.join(base_path, "pan")
            mosaic_imgs = os.listdir(mosaic_path)
            mosaic_imgs.sort()
            pan_imgs = os.listdir(pan_path)
            pan_imgs.sort()
            assert len(mosaic_imgs) == len(pan_imgs), "Length mismatch between MS and PAN images!"

            for mosaic_name, pan_name in tqdm.tqdm(tzip(mosaic_imgs, pan_imgs)):
                with open(os.path.join(mosaic_path, mosaic_name), "rb") as f:
                    mosaic_raw = numpy.frombuffer(f.read(), dtype=numpy.int16)
                    mosaic = numpy.zeros((255*4, 276*4, 1))
                    for i in range(args.msfa_size):
                        for j in range(args.msfa_size):
                            mosaic[i::args.msfa_size, j::args.msfa_size, 0] = mosaic_raw[255*276*(i*args.msfa_size+j): 255*276*(i*args.msfa_size+j+1)].reshape(255, 276)
                with open(os.path.join(pan_path, pan_name), "rb") as f:
                    pan_raw = numpy.frombuffer(f.read(), dtype=numpy.int16)
                    pan = pan_raw.reshape((255*8, 276*8, 1))
                assert pan.shape[1] % mosaic.shape[1] == 0 and pan.shape[2] % mosaic.shape[
                    2] == 0, "Mismatch between the spatial size of MS and PAN"

                for i in range(args.msfa_size):
                    for j in range(args.msfa_size):
                        mosaic[i::args.msfa_size, j::args.msfa_size, 0] = mosaic[i::args.msfa_size, j::args.msfa_size, 0] / mosaic[i::args.msfa_size, j::args.msfa_size, 0].max()
                pan = pan / pan.max((0, 1))

                mosaic_tensor = torch.from_numpy(mosaic.astype(numpy.float32)).permute(2, 0, 1).unsqueeze(0).to(f"cuda:{args.device}")
                with torch.no_grad():
                    scale_coord_map = input_matrix_wpn(mosaic_tensor.shape[2], mosaic_tensor.shape[3], 4).to(mosaic_tensor.device)
                    mosaic_up = torch.zeros(mosaic_tensor.shape[0], 4*4, mosaic_tensor.shape[2], mosaic_tensor.shape[3]).to(mosaic_tensor.device)
                    for i in range(4):
                        for j in range(4):
                            mosaic_up[:, i*4+j, i::4, j::4] = mosaic_tensor[:, 0, i::4, j::4]
                    demosaic = demosaic_net([mosaic_up, mosaic_tensor], scale_coord_map).detach()[0].cpu().numpy().transpose(1, 2, 0)

                spatial_ratio = pan.shape[0] // demosaic.shape[0]
                if type == "train":
                    demosaic_patches = crop_to_patch(demosaic, args.train_size//spatial_ratio, args.stride//spatial_ratio)
                    pan_patches = crop_to_patch(pan, args.train_size, args.stride)

                    self.lrms += demosaic_patches
                    self.pan += pan_patches

                elif type == "test":
                    self.mosaic.append(mosaic)
                    self.lrms.append(demosaic)
                    self.pan.append(pan)

            with open(cache_path, "wb") as f:
                pickle.dump([self.mosaic, self.lrms, self.pan], f)

        print("Load data from cache file: ", cache_path)
        with open(cache_path, "rb") as f:
            self.mosaic, self.lrms, self.pan = pickle.load(f)

    def __len__(self):
        return len(self.lrms)

    def __getitem__(self, index):
        if self.mosaic != []:
            mosaic = torch.from_numpy(self.mosaic[index].astype(numpy.float32))
            mosaic = mosaic.permute(2, 0, 1)
            lrms = torch.from_numpy(self.lrms[index].astype(numpy.float32))
            lrms = lrms.permute(2, 0, 1)
            pan = torch.from_numpy(self.pan[index].astype(numpy.float32))
            pan = pan.permute(2, 0, 1)

            return mosaic, lrms, pan
        else:
            lrms = torch.from_numpy(self.lrms[index].astype(numpy.float32))
            lrms = lrms.permute(2, 0, 1)
            pan = torch.from_numpy(self.pan[index].astype(numpy.float32))
            pan = pan.permute(2, 0, 1)

            return lrms, pan